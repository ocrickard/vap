# üöÄ VAP Phase 3 Training on RunPod - Deployment Guide

This guide will help you deploy and run the VAP Phase 3 optimization training on RunPod with GPU acceleration.

## üéØ Overview

**Why RunPod?**
- **GPU Acceleration**: 10-50x faster training compared to CPU
- **Cost Effective**: Pay-per-hour GPU instances
- **Scalable**: Easy to scale up/down based on needs
- **Professional**: Production-grade GPU infrastructure

**Expected Performance:**
- **CPU Training**: 30-60 minutes per epoch (estimated 25-50 hours total)
- **GPU Training**: 2-5 minutes per epoch (estimated 2-8 hours total)
- **Speed Improvement**: 10-25x faster training

## üîß Prerequisites

1. **RunPod Account**: Sign up at [runpod.io](https://runpod.io)
2. **GitHub Repository**: Your VAP code should be accessible
3. **Dataset**: LibriSpeech dataset prepared and accessible
4. **Budget**: ~$2-8 for complete training (depending on GPU type)

## üöÄ Quick Start

### Step 1: Create RunPod Instance

1. **Login to RunPod** and go to "Pods"
2. **Click "Deploy"** and select "GPU Pod"
3. **Choose Configuration**:
   - **GPU Type**: RTX 4090 (24GB VRAM) - Recommended
   - **CPU**: 8 cores
   - **RAM**: 32GB
   - **Storage**: 50GB
   - **Image**: `runpod/pytorch:2.1.1-py3.10-cuda12.1.0`

### Step 2: Deploy and Connect

1. **Deploy** the pod and wait for it to start
2. **Connect** via SSH or RunPod's web terminal
3. **Navigate** to `/workspace` directory

### Step 3: Setup Training Environment

```bash
# Clone your VAP repository
cd /workspace
git clone https://github.com/yourusername/vap.git
cd vap

# Make startup script executable
chmod +x runpod/start_training.sh

# Run the startup script
./runpod/start_training.sh
```

## üìã Detailed Configuration

### GPU Selection Guide

| GPU Type | VRAM | Speed | Cost/Hour | Recommended For |
|----------|------|-------|-----------|-----------------|
| RTX 4090 | 24GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~$0.60 | **Best Choice** |
| RTX 3090 | 24GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ~$0.50 | Good Alternative |
| RTX 3080 | 10GB | ‚≠ê‚≠ê‚≠ê | ~$0.40 | Budget Option |
| A100 | 40GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~$2.00 | Enterprise |

### Training Configuration

The RunPod configuration automatically optimizes for GPU:

```yaml
# GPU-Optimized Settings
hardware:
  precision: "16-mixed"  # Mixed precision for speed
  accelerator: "gpu"
  devices: 1
  
training:
  batch_size: 32  # Increased for GPU
  num_epochs: 50
  learning_rate: 5e-5
```

## üìä Monitoring Training

### Real-Time Progress

The RunPod training script provides comprehensive monitoring:

```
üöÄ EPOCH 1/50
===========================================================
Epoch 1: 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 439/975 [02:15<02:45, 3.24batch/s]

üìä EPOCH 1 SUMMARY
--------------------------------------------------
‚è±Ô∏è  Duration: 135.2s
üìà Train Loss: 2.8476
üìâ Val Loss: 2.2341
üéØ Val Accuracy: 0.1876
üéâ NEW BEST VALIDATION ACCURACY: 0.1876
```

### GPU Monitoring

Monitor GPU utilization in real-time:

```bash
# In another terminal
watch -n 1 nvidia-smi
```

### TensorBoard Logs

Access training logs via TensorBoard:

```bash
# Start TensorBoard
tensorboard --logdir=/workspace/logs --host=0.0.0.0 --port=6006
```

Then access via: `http://your-runpod-ip:6006`

## üíæ Data Management

### Dataset Setup

1. **Upload Dataset**: Use RunPod's file manager or SCP
2. **Directory Structure**:
   ```
   /workspace/data/realtime_dataset/
   ‚îú‚îÄ‚îÄ manifest.json
   ‚îî‚îÄ‚îÄ LibriSpeech/
       ‚îî‚îÄ‚îÄ dev-clean/
           ‚îú‚îÄ‚îÄ speaker_id/
           ‚îî‚îÄ‚îÄ chapter_id/
   ```

### Checkpoint Management

- **Automatic Saving**: Checkpoints saved every epoch
- **Best Model**: Top-3 models automatically preserved
- **Download**: Use RunPod's file manager to download results

## üîç Troubleshooting

### Common Issues

1. **Out of Memory (OOM)**
   ```bash
   # Reduce batch size in runpod_config.yaml
   training:
     batch_size: 16  # Reduce from 32
   ```

2. **Slow Training**
   - Check GPU utilization: `nvidia-smi`
   - Verify mixed precision is enabled
   - Ensure data loading isn't bottleneck

3. **Connection Issues**
   - Use RunPod's web terminal as backup
   - Check network connectivity
   - Restart pod if needed

### Performance Optimization

1. **Data Loading**:
   ```bash
   # Increase num_workers in data loader
   num_workers: 8  # Adjust based on CPU cores
   ```

2. **Mixed Precision**:
   ```yaml
   hardware:
     precision: "16-mixed"  # Ensure this is enabled
   ```

3. **Gradient Accumulation**:
   ```yaml
   training:
     accumulate_grad_batches: 2  # Effective batch size = 32 * 2 = 64
   ```

## üìà Expected Results

### Training Timeline

| Phase | Duration (GPU) | Key Metrics |
|-------|----------------|-------------|
| **Epochs 1-10** | 20-40 minutes | Loss: 2.5‚Üí1.8, Acc: 15%‚Üí25% |
| **Epochs 11-25** | 40-80 minutes | Loss: 1.8‚Üí1.2, Acc: 25%‚Üí35% |
| **Epochs 26-50** | 80-160 minutes | Loss: 1.2‚Üí0.8, Acc: 35%‚Üí45%+ |

### Performance Targets

- **Baseline Accuracy**: 10.95% (Phase 2)
- **Target Accuracy**: >25% improvement
- **Expected Final**: 35-45% overall accuracy
- **Training Time**: 2-8 hours (vs 25-50 hours on CPU)

## üí∞ Cost Estimation

### RTX 4090 Training

- **Per Hour**: ~$0.60
- **Total Training**: 2-8 hours
- **Total Cost**: $1.20 - $4.80
- **Cost per Epoch**: $0.02 - $0.10

### Cost Comparison

| Platform | Time | Cost | Speed |
|----------|------|------|-------|
| **Local CPU** | 25-50 hours | $0 | 1x |
| **RunPod RTX 4090** | 2-8 hours | $1.20-$4.80 | 10-25x |
| **Cloud GPU** | 2-8 hours | $10-$50 | 10-25x |

## üéâ Success Checklist

- [ ] RunPod instance deployed with RTX 4090
- [ ] VAP repository cloned and setup
- [ ] Dataset uploaded to `/workspace/data/realtime_dataset/`
- [ ] Training script running with GPU acceleration
- [ ] Real-time progress monitoring active
- [ ] Checkpoints saving successfully
- [ ] Training completed in <8 hours
- [ ] Results downloaded and analyzed

## üöÄ Next Steps

After successful training:

1. **Download Results**: Checkpoints, logs, and evaluation results
2. **Local Testing**: Test the trained model locally
3. **Performance Analysis**: Compare with baseline results
4. **Model Deployment**: Deploy optimized model for inference
5. **Phase 4 Planning**: Plan next optimization phase

## üìû Support

- **RunPod Issues**: [RunPod Support](https://runpod.io/support)
- **Training Issues**: Check logs in `/workspace/logs/`
- **Performance Issues**: Monitor GPU utilization and memory

---

**Happy Training! üöÄüî•**

Your VAP Phase 3 optimization will be 10-25x faster on RunPod compared to local CPU training! 