#!/usr/bin/env python3
"""
Local Test Script for RunPod Training - VAP Phase 3

This script tests the RunPod training pipeline locally on macOS
before deploying to RunPod GPU instances.
"""

import os
import sys
import logging
import json
import time
import yaml
from pathlib import Path
from datetime import datetime
import torch
import torch.nn.functional as F
import pytorch_lightning as pl
from pytorch_lightning.callbacks import (
    ModelCheckpoint, EarlyStopping, LearningRateMonitor, 
    RichProgressBar
)
from pytorch_lightning.loggers import TensorBoardLogger
import numpy as np
from tqdm import tqdm

# Add the project root to the path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from vap.models.vap_model import VAPTurnDetector
from vap.tasks.turn_detection_task import VAPTurnDetectionTask
from vap.data.simple_loader import SimpleAudioDataset

# Configure logging for local environment
log_dir = project_root / "logs" / "local_test"
log_dir.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / "local_training.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class LocalProgressTracker:
    """Progress tracker for local testing"""
    
    def __init__(self, total_epochs, total_train_batches, total_val_batches):
        self.total_epochs = total_epochs
        self.total_train_batches = total_train_batches
        self.total_val_batches = total_val_batches
        self.current_epoch = 0
        self.start_time = time.time()
        self.epoch_start_time = time.time()
        
        # Metrics tracking
        self.train_metrics = {}
        self.val_metrics = {}
        self.best_val_accuracy = 0.0
        
        # Training statistics
        self.epoch_times = []
        self.train_losses = []
        self.val_losses = []
        self.val_accuracies = []
        
        # Display initial status
        self._display_local_header()
    
    def _display_local_header(self):
        """Display local testing header"""
        logger.info("\n" + "="*80)
        logger.info("üöÄ VAP TURN DETECTOR - PHASE 3 LOCAL TESTING")
        logger.info("="*80)
        logger.info(f"üíª Local Testing Configuration:")
        logger.info(f"   ‚Ä¢ Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
        logger.info(f"   ‚Ä¢ PyTorch Version: {torch.__version__}")
        logger.info(f"   ‚Ä¢ Total Epochs: {self.total_epochs}")
        logger.info(f"   ‚Ä¢ Train Batches per Epoch: {self.total_train_batches}")
        logger.info(f"   ‚Ä¢ Val Batches per Epoch: {self.total_val_batches}")
        logger.info(f"   ‚Ä¢ Estimated Total Batches: {self.total_epochs * (self.total_train_batches + self.total_val_batches):,}")
        logger.info("="*80)
    
    def start_epoch(self, epoch):
        """Start tracking a new epoch"""
        self.current_epoch = epoch
        self.epoch_start_time = time.time()
        
        logger.info(f"\nüöÄ EPOCH {epoch}/{self.total_epochs}")
        logger.info("="*60)
    
    def end_epoch(self, train_loss, val_loss, val_accuracy):
        """End epoch tracking"""
        epoch_time = time.time() - self.epoch_start_time
        self.epoch_times.append(epoch_time)
        self.train_losses.append(train_loss)
        self.val_losses.append(val_loss)
        self.val_accuracies.append(val_accuracy)
        
        # Check for best accuracy
        if val_accuracy > self.best_val_accuracy:
            self.best_val_accuracy = val_accuracy
            logger.info(f"üéâ NEW BEST VALIDATION ACCURACY: {val_accuracy:.4f}")
        
        # Display epoch summary
        logger.info(f"\nüìä EPOCH {self.current_epoch} SUMMARY")
        logger.info("-" * 50)
        logger.info(f"‚è±Ô∏è  Duration: {epoch_time:.1f}s")
        logger.info(f"üìà Train Loss: {train_loss:.4f}")
        logger.info(f"üìâ Val Loss: {val_loss:.4f}")
        logger.info(f"üéØ Val Accuracy: {val_accuracy:.4f}")
        
        # Training progress summary
        completed_epochs = len(self.epoch_times)
        total_time = time.time() - self.start_time
        avg_epoch_time = np.mean(self.epoch_times)
        estimated_remaining = avg_epoch_time * (self.total_epochs - completed_epochs)
        
        logger.info(f"\nüìà TRAINING PROGRESS SUMMARY")
        logger.info("-" * 40)
        logger.info(f"Completed Epochs: {completed_epochs}/{self.total_epochs}")
        logger.info(f"Progress: {(completed_epochs/self.total_epochs)*100:.1f}%")
        logger.info(f"Average Epoch Time: {avg_epoch_time:.1f}s")
        logger.info(f"Total Training Time: {total_time/60:.1f} minutes")
        logger.info(f"Estimated Time Remaining: {estimated_remaining/60:.1f} minutes")
        logger.info(f"Best Validation Accuracy: {self.best_val_accuracy:.4f}")
        
        # Trend analysis
        if len(self.val_accuracies) >= 2:
            recent_trend = "‚ÜóÔ∏è Improving" if self.val_accuracies[-1] > self.val_accuracies[-2] else "‚ÜòÔ∏è Declining"
            logger.info(f"Recent Trend: {recent_trend}")

def test_local_training():
    """Test the training pipeline locally"""
    logger.info("üß™ Testing local training pipeline...")
    
    try:
        # Load configuration
        config_path = project_root / "configs" / "vap_optimized.yaml"
        if not config_path.exists():
            logger.error(f"‚ùå Configuration file not found: {config_path}")
            return False
        
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # Ensure numeric values are properly typed
        config['training']['learning_rate'] = float(config['training']['learning_rate'])
        config['training']['weight_decay'] = float(config['training']['weight_decay'])
        
        logger.info("‚úÖ Configuration loaded successfully")
        logger.info(f"   ‚Ä¢ Learning Rate: {config['training']['learning_rate']} (type: {type(config['training']['learning_rate'])})")
        logger.info(f"   ‚Ä¢ Weight Decay: {config['training']['weight_decay']} (type: {type(config['training']['weight_decay'])})")
        
        # Check if dataset exists
        dataset_path = project_root / "data" / "realtime_dataset"
        if not dataset_path.exists():
            logger.error(f"‚ùå Dataset not found: {dataset_path}")
            return False
        
        logger.info("‚úÖ Dataset found")
        
        # Test model creation
        logger.info("üîß Testing model creation...")
        model = VAPTurnDetector(
            hidden_dim=config['model']['hidden_dim'],
            num_layers=config['model']['num_layers'],
            num_heads=config['model']['num_heads']
        )
        
        # Count parameters
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        logger.info(f"‚úÖ Model created successfully:")
        logger.info(f"   ‚Ä¢ Total Parameters: {total_params:,}")
        logger.info(f"   ‚Ä¢ Trainable Parameters: {trainable_params:,}")
        logger.info(f"   ‚Ä¢ Model Size: {total_params * 4 / (1024*1024):.1f} MB")
        
        # Test data loading
        logger.info("üìä Testing data loading...")
        dataset = SimpleAudioDataset(
            manifest_path=str(dataset_path / "manifest.json"),
            audio_root=str(dataset_path / "LibriSpeech"),
            max_duration=config['data']['max_duration']
        )
        
        logger.info(f"‚úÖ Dataset loaded successfully:")
        logger.info(f"   ‚Ä¢ Total Files: {len(dataset)}")
        logger.info(f"   ‚Ä¢ Sample Rate: {config['data']['sample_rate']} Hz")
        logger.info(f"   ‚Ä¢ Max Duration: {config['data']['max_duration']}s")
        
        # Test model forward pass
        logger.info("üöÄ Testing model forward pass...")
        sample_audio_a = torch.randn(1, 16000 * 5)  # 5 seconds of audio for speaker A
        sample_audio_b = torch.randn(1, 16000 * 5)  # 5 seconds of audio for speaker B
        with torch.no_grad():
            outputs = model(sample_audio_a, sample_audio_b)
        
        logger.info("‚úÖ Model forward pass successful:")
        for key, value in outputs.items():
            if isinstance(value, torch.Tensor):
                logger.info(f"   ‚Ä¢ {key}: {value.shape}")
            else:
                logger.info(f"   ‚Ä¢ {key}: {value}")
        
        # Test training task creation
        logger.info("üéØ Testing training task creation...")
        task = VAPTurnDetectionTask(
            model=model,
            learning_rate=config['training']['learning_rate'],
            weight_decay=config['training']['weight_decay']
        )
        
        logger.info("‚úÖ Training task created successfully")
        
        # Test PyTorch Lightning trainer
        logger.info("‚ö° Testing PyTorch Lightning integration...")
        trainer = pl.Trainer(
            max_epochs=1,  # Just test 1 epoch
            accelerator='auto',
            devices=1,
            logger=False,
            enable_checkpointing=False,
            enable_progress_bar=True,
            callbacks=[RichProgressBar()]
        )
        
        logger.info("‚úÖ PyTorch Lightning trainer created successfully")
        
        # Test with a small subset of data
        logger.info("üß™ Testing training with small dataset...")
        
        # Create a simple batch format that matches what the training task expects
        # For testing, we'll use the same audio for both speakers
        def create_test_batch(audio_tensor):
            # Get the actual output dimensions from the model
            with torch.no_grad():
                test_outputs = model(audio_tensor.unsqueeze(0), audio_tensor.unsqueeze(0))
            
            # Debug: Print the actual output shapes
            logger.info("üîç Model output shapes:")
            for key, value in test_outputs.items():
                if isinstance(value, torch.Tensor):
                    logger.info(f"   ‚Ä¢ {key}: {value.shape}")
            
            # Extract the exact dimensions from the outputs
            batch_size, time_steps, num_classes = test_outputs['vap_logits'].shape
            
            logger.info(f"üîç Creating labels with dimensions: batch={batch_size}, time={time_steps}, classes={num_classes}")
            
            return {
                'audio_a': audio_tensor.unsqueeze(0),  # Add batch dimension
                'audio_b': audio_tensor.unsqueeze(0),  # Same audio for both speakers
                'vap_labels': torch.randint(0, num_classes, (batch_size, time_steps)),  # Class indices [batch, time]
                'eot_labels': torch.zeros(batch_size, time_steps),                       # Binary labels [batch, time]
                'backchannel_labels': torch.zeros(batch_size, time_steps),               # Binary labels [batch, time]
                'overlap_labels': torch.zeros(batch_size, time_steps),                   # Binary labels [batch, time]
                'vad_labels': torch.zeros(batch_size, time_steps, 2)                    # Binary labels [batch, time, 2]
            }
        
        # Test with just one sample to avoid batch processing issues
        test_sample = dataset[0]
        test_batch = create_test_batch(test_sample['audio'])
        
        logger.info("‚úÖ Test batch created successfully")
        logger.info(f"   ‚Ä¢ Audio A shape: {test_batch['audio_a'].shape}")
        logger.info(f"   ‚Ä¢ Audio B shape: {test_batch['audio_b'].shape}")
        logger.info(f"   ‚Ä¢ VAP labels shape: {test_batch['vap_labels'].shape}")
        
        # Test the training step manually
        logger.info("üß™ Testing training step manually...")
        with torch.no_grad():
            loss = task.training_step(test_batch, 0)
        
        logger.info(f"‚úÖ Training step successful! Loss: {loss:.4f}")
        
        logger.info("‚úÖ Training test completed successfully!")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Local testing failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main function for local testing"""
    logger.info("üöÄ Starting VAP Phase 3 Local Testing")
    logger.info("="*50)
    
    success = test_local_training()
    
    if success:
        logger.info("\nüéâ Local testing completed successfully!")
        logger.info("‚úÖ All components are working correctly")
        logger.info("üöÄ Ready for RunPod deployment!")
    else:
        logger.error("\n‚ùå Local testing failed!")
        logger.error("Please fix the issues before deploying to RunPod")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1) 