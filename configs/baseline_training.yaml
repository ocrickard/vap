data:
  max_duration: 30.0
  num_workers: 0
  train_split: 0.8
  val_split: 0.2
evaluation:
  eval_interval: 1
  patience: 5
  save_top_k: 3
model:
  dropout: 0.1
  hidden_dim: 128
  num_heads: 4
  num_layers: 2
training:
  accumulate_grad_batches: 2
  batch_size: 8
  gradient_clip_val: 1.0
  learning_rate: 0.0001
  max_epochs: 10
  weight_decay: 1.0e-05
